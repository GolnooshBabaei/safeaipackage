# SAFE AI

To fulfill trustworthiness, Artificial Intelligence (AI) methods need to be safe. SAFE referes to an AI based model for risk measures are controlled. 
The general risks of AI can be considered in the following types: Privacy, Robustness, Accuracy, Fairness, and Explainability.
In other words, a safe application of AI must satisfy these basic key-principles. 

# Install
safeaipackage can be installed from TestPyPI as follows:

pip install -i https://test.pypi.org/simple/safeaipackage==0.0.1


# Citations
The algorithms and visualizations used in this package came primarily out of research by 
[Paolo Giudici](https://www.linkedin.com/in/paolo-giudici-60028a/), [Emanuela Raffinetti](https://www.linkedin.com/in/emanuela-raffinetti-a3980215/), 
and [Golnoosh Babaei](https://www.linkedin.com/in/golnoosh-babaei-990077187/) in the [Statistical laboratory](https://sites.google.com/unipv.it/statslab-pavia/home?authuser=0) 
at the University of Pavia. If you use safe_ai package in your research we would appreciate a citation to the appropriate paper(s):
* For the RGA measure introduced in "check_accuracy" module, you can read/cite [this paper](https://link.springer.com/article/10.1007/s11135-023-01613-y)

